{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gestures_capsnet",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvp-QjdfG1tw",
        "colab_type": "code",
        "outputId": "2c52347f-a195-4dbe-93fd-3a36a480bc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# !pip install -U -q PyDrive\n",
        "!pip install -q --upgrade ipython==5.5.0\n",
        "!pip uninstall ipykernal\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping ipykernal as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zjZVHGxq2v2",
        "colab_type": "code",
        "outputId": "0f040da4-a928-4c85-95c4-763a9799c482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q --upgrade ipykernel==4.6.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▏                            | 10kB 28.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxYCUEnqHuuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pydrive.auth import GoogleAuth\n",
        "\n",
        "# from pydrive.drive import GoogleDrive\n",
        "\n",
        "# from google.colab import auth\n",
        "\n",
        "# from oauth2client.client import GoogleCredentials \n",
        "\n",
        "\n",
        "# # 1. Authenticate and create the PyDrive client. \n",
        "\n",
        "# auth.authenticate_user()\n",
        "\n",
        "# gauth = GoogleAuth()\n",
        "\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "\n",
        "# drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj4BcSb3CMRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c8a397b4-70cc-49ea-9e11-d29332e34540"
      },
      "source": [
        "!pip uninstall torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.3.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.6/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-1.3.1.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torch-1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdWqk_CC6997",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "82d94fd4-95e3-4ef8-e6de-1a807d5cb83c"
      },
      "source": [
        "!pip install torch==0.3.1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/a5/e8b50b55b1abac9f1e3346c4242f1e42a82d368a8442cbd50c532922f6c4/torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (496.4MB)\n",
            "\u001b[K     |████████████████████████████████| 496.4MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.1) (1.17.4)\n",
            "\u001b[31mERROR: torchvision 0.4.2 has requirement torch==1.3.1, but you'll have torch 0.3.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.59 has requirement torch>=1.0.0, but you'll have torch 0.3.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQOlTc5LCi3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "ca5b712c-58fa-472d-deaa-4ecb17ea83f5"
      },
      "source": [
        "!pip uninstall torchvision"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torchvision-0.4.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.4.2.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled torchvision-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYW_T7EHCDPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "7a2a92bf-b0d0-4c90-e99c-f5abe2432a04"
      },
      "source": [
        "!pip install torchvision==0.2.1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.17.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (4.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (0.3.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.1) (0.46)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==0.2.1) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGR4Cb2WCDSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "277896f5-da3c-4dba-a4ac-ee52cb85738d"
      },
      "source": [
        "!pip install torchnet"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchnet in /usr/local/lib/python3.6/dist-packages (0.0.4)\n",
            "Requirement already satisfied: visdom in /usr/local/lib/python3.6/dist-packages (from torchnet) (0.1.8.9)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchnet) (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchnet) (1.12.0)\n",
            "Requirement already satisfied: torchfile in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (0.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (1.17.4)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (0.57.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (17.0.0)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (1.24)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (2.21.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom->torchnet) (4.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchnet) (3.13)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.6/dist-packages (from jsonpatch->visdom->torchnet) (2.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom->torchnet) (2019.11.28)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->visdom->torchnet) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gh-L-QgCDVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef75dd98-9279-4ac7-f6de-033af311bc67"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC1pFxKUHu34",
        "colab_type": "code",
        "outputId": "97f8386e-f579-4d37-ce27-ecd0fd3fbabb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhhcRYLS_KKg",
        "colab_type": "code",
        "outputId": "5e70b941-740f-4222-d9bc-a0541b6b2437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/'My Drive'/gestures"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gestures\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Lvwjay_T8c",
        "colab_type": "code",
        "outputId": "8fccb593-9bd1-47e0-b0cb-4a9fa9401a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "capsnet_gestures_ver-Copy4.ipynb  data\tepoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_LjJxY8Hehf",
        "colab_type": "code",
        "outputId": "2060d66d-9e45-4ae3-b1ff-13095973b0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install SimpleITK"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 75kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x97W1igFy57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from tqdm import tqdm\n",
        "import torchnet as tnt\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7AR50ilFzGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "NUM_CLASSES = 5\n",
        "NUM_EPOCHS = 200\n",
        "NUM_ROUTING_ITERATIONS = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xpa4SRQFzOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import torch, os, glob, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from visdom import Visdom\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hplu4ccHbua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_classes(dir):\n",
        "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
        "    classes.sort()\n",
        "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "    return classes, class_to_idx\n",
        "\n",
        "def make_dataset(dir, class_to_idx):\n",
        "    images = []\n",
        "    dir = os.path.expanduser(dir)\n",
        "    for target in sorted(os.listdir(dir)):\n",
        "        d = os.path.join(dir, target)\n",
        "        if not os.path.isdir(d):\n",
        "            continue\n",
        "\n",
        "        for root, _, fnames in sorted(os.walk(d)):\n",
        "            for fname in sorted(fnames):\n",
        "                path = os.path.join(root, fname)\n",
        "                item = (path, class_to_idx[target])\n",
        "                images.append(item)\n",
        "\n",
        "    return images\n",
        "\n",
        "def reader(path):\n",
        "    img =sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
        "    #img = cv2.resize(img, (224,224))\n",
        "    #img = np.expand_dims(img, axis=0)\n",
        "    #img = np.concatenate([img,img,img], axis=0).transpose((1,2,0)).astype(np.float32)\n",
        "    return img\n",
        "def resize_img(img):\n",
        "    gray_img = img.transpose((2,0,1))[0]\n",
        "    resize_gray_img = cv2.resize(gray_img, (160,120))\n",
        "    return resize_gray_img    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raNhbcjhHnaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DicomFolder(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        classes, class_to_idx = find_classes(root)\n",
        "        imgs = make_dataset(root, class_to_idx)\n",
        "        \n",
        "        if len(imgs)==0:\n",
        "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"))\n",
        "        \n",
        "        self.root = root\n",
        "        self.imgs = imgs\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        path, label = self.imgs[index]\n",
        "        \n",
        "        img = reader(path)\n",
        "        resized_img = resize_img(img)\n",
        "        #dicom=cv2.resize(dicom,(160,120))\n",
        "       \n",
        "        #dicom = np.expand_dims(cv2.resize(self.loader(path)[0], (224,224)), axis=2).astype(np.float32)\n",
        "        \n",
        "        return resized_img, label\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thx8PlTIZX-V",
        "colab_type": "code",
        "outputId": "8d862c32-0057-45b6-f82a-9cd385f332d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "torch.eye(NUM_CLASSES)[3].type(torch.LongTensor).view(1,-1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              " 0  0  0  1  0\n",
              "[torch.LongTensor of size 1x5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63z_LrQwHncD",
        "colab_type": "code",
        "outputId": "02c026dd-3591-4fdd-e093-0309e915f582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_dset = DicomFolder('/content/drive/My Drive/gestures/data/01except/')\n",
        "val_dset = DicomFolder('/content/drive/My Drive/gestures/data/01/')\n",
        "dsets = {'train':train_dset, 'val':val_dset}\n",
        "dset_loaders = {x: DataLoader(dsets[x], batch_size=1,\n",
        "                            shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}\n",
        "dset_classes = dsets['train'].classes\n",
        "dset_classes"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c', 'g', 'h', 'o', 't']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMnYSAUeZgWO",
        "colab_type": "code",
        "outputId": "2edc46f5-3e83-4702-a5f2-452078306f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dset = DicomFolder('/content/drive/My Drive/gestures/data/01/')\n",
        "test_dsets = {'test':test_dset}\n",
        "test_loaders = {x: DataLoader(test_dsets[x], batch_size=1,\n",
        "                            shuffle=True, num_workers=4) for x in ['test']}\n",
        "test_sizes = {x: len(test_dsets[x]) for x in ['test']}\n",
        "test_classes = test_dsets['test'].classes\n",
        "test_classes\n",
        "# test_sizes"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c', 'g', 'h', 'o', 't']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrMuIZKUZgZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(input, dim=1):\n",
        "    transposed_input = input.transpose(dim, len(input.size()) - 1)\n",
        "    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)))\n",
        "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) - 1)\n",
        "\n",
        "\n",
        "def augmentation(x, max_shift=2):\n",
        "    _, _, height, width = x.size()\n",
        "\n",
        "    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n",
        "    source_height_slice = slice(max(0, h_shift), h_shift + height)\n",
        "    source_width_slice = slice(max(0, w_shift), w_shift + width)\n",
        "    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n",
        "    target_width_slice = slice(max(0, -w_shift), -w_shift + width)\n",
        "\n",
        "    shifted_image = torch.zeros(*x.size())\n",
        "    shifted_image[:, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n",
        "    return shifted_image.float()\n",
        "\n",
        "\n",
        "class CapsuleLayer(nn.Module):\n",
        "    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels, kernel_size=None, stride=None,\n",
        "                 num_iterations=NUM_ROUTING_ITERATIONS):\n",
        "        super(CapsuleLayer, self).__init__()\n",
        "\n",
        "        self.num_route_nodes = num_route_nodes\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        if num_route_nodes != -1:\n",
        "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n",
        "        else:\n",
        "            self.capsules = nn.ModuleList(\n",
        "                [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for _ in\n",
        "                 range(num_capsules)])\n",
        "\n",
        "    def squash(self, tensor, dim=-1):\n",
        "        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n",
        "        scale = squared_norm / (1 + squared_norm)\n",
        "        return scale * tensor / torch.sqrt(squared_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.num_route_nodes != -1:\n",
        "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
        "\n",
        "            logits = Variable(torch.zeros(*priors.size())).cuda()\n",
        "            for i in range(self.num_iterations):\n",
        "                probs = softmax(logits, dim=2)\n",
        "                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n",
        "\n",
        "                if i != self.num_iterations - 1:\n",
        "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
        "                    logits = logits + delta_logits\n",
        "        else:\n",
        "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
        "            outputs = torch.cat(outputs, dim=-1)\n",
        "            outputs = self.squash(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class CapsuleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsuleNet, self).__init__()\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
        "#         self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n",
        "#                                              kernel_size=9, stride=2)\n",
        "#         self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=32 * 52 *72, in_channels=8,\n",
        "#                                            out_channels=16)\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
        "        self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n",
        "                                             kernel_size=9, stride=2)\n",
        "        self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=32 * 52 *72, in_channels=8,\n",
        "                                           out_channels=16)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16 * NUM_CLASSES, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2048, 120*160),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = F.relu(self.conv1(x), inplace=True)\n",
        "        \n",
        "       \n",
        "        x = self.primary_capsules(x)\n",
        "        #print(x.size())\n",
        "        z = self.digit_capsules(x)\n",
        "        #print(z.size())\n",
        "        x=z.squeeze().unsqueeze(0)\n",
        "        #x=z.squeeze().transpose(0, 1)\n",
        "        #print(x.size())\n",
        "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
        "        classes = F.softmax(classes)\n",
        "        #print(classes.size())\n",
        "        if y is None:\n",
        "            # In all batches, get the most active capsule.\n",
        "            _, max_length_indices = classes.max(dim=1)\n",
        "\n",
        "\n",
        "##수정\n",
        "            masked = Variable(torch.sparse.torch.eye(NUM_CLASSES))\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                y = masked.cuda().index_select(dim=0, index=max_length_indices.data)\n",
        "\n",
        "            # if torch.cuda.is_available():\n",
        "            #     y = Variable(torch.sparse.torch.eye(NUM_CLASSES)).cuda().index_select(dim=0, index=max_length_indices.data)\n",
        "            # else:\n",
        "            #     y = Variable(torch.sparse.torch.eye(NUM_CLASSES)).index_select(dim=0, index=max_length_indices.data)\n",
        "\n",
        "  \n",
        "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
        "        #print(reconstructions.size())\n",
        "  \n",
        "        return classes, reconstructions\n",
        "\n",
        "\n",
        "class CapsuleLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsuleLoss, self).__init__()\n",
        "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
        "\n",
        "    def forward(self, images, labels, classes, reconstructions):\n",
        "        left = F.relu(0.9 - classes, inplace=True) ** 2\n",
        "        right = F.relu(classes - 0.1, inplace=True) ** 2\n",
        "\n",
        "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
        "        margin_loss = margin_loss.sum()\n",
        "\n",
        "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
        "\n",
        "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLCkdk12tMBA",
        "colab_type": "code",
        "outputId": "c2a2a3fe-e723-48be-eda3-2cf4828aab41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from tqdm import tqdm\n",
        "import torchnet as tnt\n",
        "\n",
        "model = CapsuleNet()\n",
        "# model.load_state_dict(torch.load('epochs/epoch_327.pt'))\n",
        "model.cuda()\n",
        "\n",
        "print(\"# parameters:\", sum(param.numel() for param in model.parameters()))\n",
        "\n",
        "optimizer = Adam(model.parameters())\n",
        "\n",
        "engine = Engine()\n",
        "meter_loss = tnt.meter.AverageValueMeter()\n",
        "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n",
        "\n",
        "# train_loss_logger = VisdomPlotLogger('line', opts={'title': '120160_layer Train Loss'})\n",
        "# train_error_logger = VisdomPlotLogger('line', opts={'title': '120160_layer Train Accuracy'})\n",
        "# test_loss_logger = VisdomPlotLogger('line', opts={'title': '120160_layer Test Loss'})\n",
        "# test_accuracy_logger = VisdomPlotLogger('line', opts={'title': '120160_layer Test Accuracy'})\n",
        "# confusion_logger = VisdomLogger('heatmap', opts={'title': '120160_layer Confusion matrix',\n",
        "#                                                  'columnnames': list(range(NUM_CLASSES)),\n",
        "#                                                  'rownames': list(range(NUM_CLASSES))})\n",
        "# ground_truth_logger = VisdomLogger('image', opts={'title': '120160_layer Ground Truth'})\n",
        "# reconstruction_logger = VisdomLogger('image', opts={'title': '120160_layer Reconstruction'})\n",
        "\n",
        "capsule_loss = CapsuleLoss()\n",
        "\n",
        "\n",
        "def get_iterator(mode):\n",
        "    \n",
        "    #dataset = MNIST(root='./data', download=True, train=mode)\n",
        "    #data = getattr(dataset, 'train_data' if mode else 'test_data')\n",
        "    #labels = getattr(dataset, 'train_labels' if mode else 'test_labels')\n",
        "\n",
        "    d,l =  next(iter(dset_loaders['train']))\n",
        "    tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
        "\n",
        "    return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n",
        "\n",
        "\n",
        "def processor(sample):\n",
        "    data, labels, training = sample\n",
        "\n",
        "    data = augmentation(data.unsqueeze(1).float() / 255.0)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "\n",
        "    data = Variable(data).cuda()\n",
        "    labels = Variable(labels).cuda()\n",
        "\n",
        "    if training:\n",
        "        classes, reconstructions = model(data, labels)\n",
        "    else:\n",
        "        classes, reconstructions = model(data)\n",
        "\n",
        "    loss = capsule_loss(data, labels, classes, reconstructions)\n",
        "\n",
        "    return loss, classes\n",
        "\n",
        "\n",
        "def reset_meters():\n",
        "    meter_accuracy.reset()\n",
        "    meter_loss.reset()\n",
        "    confusion_meter.reset()\n",
        "\n",
        "\n",
        "def on_sample(state):\n",
        "    state['sample'].append(state['train'])\n",
        "\n",
        "\n",
        "def on_forward(state):\n",
        "    meter_accuracy.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
        "    #print(state['output'].data.size())\n",
        "    #print(torch.LongTensor(state['sample'][1]).size())\n",
        "    one_hot = torch.eye(NUM_CLASSES)[torch.LongTensor(state['sample'][1])].type(torch.LongTensor).view(1,-1)\n",
        "    #print('onehot',one_hot)\n",
        "    #confusion_meter.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
        "    confusion_meter.add(state['output'].data, one_hot)\n",
        "    \n",
        "    meter_loss.add(state['loss'].data[0])\n",
        "\n",
        "\n",
        "def on_start_epoch(state):\n",
        "    reset_meters()\n",
        "    state['iterator'] = tqdm(state['iterator'])\n",
        "\n",
        "\n",
        "def on_end_epoch(state):\n",
        "    print('[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "\n",
        "    # train_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
        "    # train_error_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
        "\n",
        "    reset_meters()\n",
        "\n",
        "    #engine.test(processor, get_iterator(False))\n",
        "    engine.test(processor, dset_loaders['val'])    \n",
        "\n",
        "    # test_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
        "    # test_accuracy_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
        "    # confusion_logger.log(confusion_meter.value())\n",
        "\n",
        "    print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/drive/My Drive/gestures/epoch/01_ep/epoch_%d.pt' % state['epoch'])\n",
        "\n",
        "    # Reconstruction visualization.\n",
        "\n",
        "    test_sample = next(iter(dset_loaders['val']))\n",
        "\n",
        "    ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n",
        "    _, reconstructions = model(Variable(ground_truth).cuda())\n",
        "    reconstruction = reconstructions.cpu().view_as(ground_truth).data\n",
        "\n",
        "    # ground_truth_logger.log(\n",
        "    #     make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
        "    # reconstruction_logger.log(\n",
        "    #     make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
        "\n",
        "# def on_start(state):\n",
        "#     state['epoch'] = 327\n",
        "#\n",
        "# engine.hooks['on_start'] = on_start\n",
        "engine.hooks['on_sample'] = on_sample\n",
        "engine.hooks['on_forward'] = on_forward\n",
        "engine.hooks['on_start_epoch'] = on_start_epoch\n",
        "engine.hooks['on_end_epoch'] = on_end_epoch\n",
        "\n",
        "engine.train(processor, dset_loaders['train'], maxepoch=NUM_EPOCHS, optimizer=optimizer)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/795 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "# parameters: 123529728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:109: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "100%|██████████| 795/795 [01:52<00:00,  7.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1] Training Loss: 0.6801 (Accuracy: 23.14%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-bed778b12678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'on_end_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mon_end_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchnet/engine/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, network, iterator, maxepoch, optimizer)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_end_epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchnet/engine/engine.py\u001b[0m in \u001b[0;36mhook\u001b[0;34m(self, name, state)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \"\"\"\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-bed778b12678>\u001b[0m in \u001b[0;36mon_end_epoch\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m#engine.test(processor, get_iterator(False))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# test_loss_logger.log(state['epoch'], meter_loss.value()[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchnet/engine/engine.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, network, iterator)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchnet/engine/engine.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'network'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-bed778b12678>\u001b[0m in \u001b[0;36mprocessor\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapsule_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-9aa64ddd0d96>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# if torch.cuda.is_available():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: index_select(): argument 'index' must be Variable, not torch.cuda.LongTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_-Kx4TNZ3k7",
        "colab_type": "text"
      },
      "source": [
        "inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cAPTKdQZmA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from tqdm import tqdm\n",
        "import torchnet as tnt\n",
        "\n",
        "model = CapsuleNet()\n",
        "\n",
        "model.load_state_dict(torch.load('/data2/ar/gestures20170903/epoch/200250/epoch_198.pt'))\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRFb3_xlF5oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMSXMCcIZ7ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHTdXksCZ7rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"# parameters:\", sum(param.numel() for param in model.parameters()))\n",
        "\n",
        "optimizer = Adam(model.parameters())\n",
        "engine = Engine()\n",
        "meter_loss = tnt.meter.AverageValueMeter()\n",
        "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n",
        "\n",
        "train_loss_logger = VisdomPlotLogger('line', opts={'title': 'Train Loss'})\n",
        "train_error_logger = VisdomPlotLogger('line', opts={'title': 'Train Accuracy'})\n",
        "test_loss_logger = VisdomPlotLogger('line', opts={'title': 'Test Loss'})\n",
        "test_accuracy_logger = VisdomPlotLogger('line', opts={'title': 'Test Accuracy'})\n",
        "confusion_logger = VisdomLogger('heatmap', opts={'title': 'Confusion matrix',\n",
        "                                                 'columnnames': list(range(NUM_CLASSES)),\n",
        "                                                 'rownames': list(range(NUM_CLASSES))})\n",
        "ground_truth_logger = VisdomLogger('image', opts={'title': 'Ground Truth'})\n",
        "reconstruction_logger = VisdomLogger('image', opts={'title': 'Reconstruction'})\n",
        "\n",
        "capsule_loss = CapsuleLoss()\n",
        "\n",
        "# def test_processor(sample):\n",
        "#     data, labels = sample\n",
        "\n",
        "#     data = augmentation(data.unsqueeze(1).float() )\n",
        "#     labels = torch.LongTensor(labels)\n",
        "\n",
        "#     labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "\n",
        "#     data = Variable(data).cuda()\n",
        "#     labels = Variable(labels).cuda()\n",
        "\n",
        "# #     if training:\n",
        "#     classes, reconstructions = model(data, labels)\n",
        "# #     else:\n",
        "# #         classes, reconstructions = model(data)\n",
        "\n",
        "#     print(labels , classes)\n",
        "#     loss = capsule_loss(data, labels, classes, reconstructions)\n",
        "\n",
        "#     return loss, classes\n",
        "\n",
        "\n",
        "def get_digit_caps(model, image):\n",
        "    input_ = Variable(image.unsqueeze(0), volatile=True)\n",
        "    \n",
        "    digit_caps, probs = model.capsnet(input_)\n",
        "    return digit_caps\n",
        "\n",
        "# takes digit_caps output and target label\n",
        "def get_reconstruction(model, digit_caps, label):\n",
        "    target = Variable(torch.LongTensor([label]), volatile=True)\n",
        "    reconstruction = model.reconstruction_net(digit_caps, target)\n",
        "    return reconstruction.data.cpu().numpy()[0].reshape(28, 28)\n",
        "\n",
        "# create reconstructions with perturbed digit capsule\n",
        "def dimension_perturbation_reconstructions(model, digit_caps, label, dimension, dim_values):\n",
        "    reconstructions = []\n",
        "    for dim_value in dim_values:\n",
        "        digit_caps_perturbed = digit_caps.clone()\n",
        "        digit_caps_perturbed[0, label, dimension] = dim_value\n",
        "        reconstruction = get_reconstruction(model, digit_caps_perturbed, label)\n",
        "        reconstructions.append(reconstruction)\n",
        "    return reconstructions\n",
        "\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "#     engine.test(test_processor, test_loaders['test'])  \n",
        "    \n",
        "    data, labels = test_loaders['test']\n",
        "    data = augmentation(data.unsqueeze(1).float() )\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "\n",
        "    data1 = Variable(data).cuda()\n",
        "    labels = Variable(labels).cuda()\n",
        "    \n",
        "    y_pred, x_recon = model(data1)\n",
        "    \n",
        "    test_loss +=capsule_loss(data1, labels, y_pred, x_recon)\n",
        "    y_pred = y_pred.data.max(1)[1]\n",
        "    y_true = data1.data.max(1)[1]\n",
        "    correct += y_pred.eq(y_true).cpu().sum()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    return test_loss, correct / len(test_loader.dataset)        \n",
        "\n",
        "test_acc=[]\n",
        "test_loss=[]\n",
        "# def test_processor(sample):\n",
        "#     test_loss = 0\n",
        "#     correct = 0\n",
        "#     data, labels= sample\n",
        "\n",
        "#     data = augmentation(data.unsqueeze(1).float() )\n",
        "#     labels = torch.LongTensor(labels)\n",
        "\n",
        "#     labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "\n",
        "#     data = Variable(data).cuda()\n",
        "#     labels = Variable(labels).cuda()\n",
        "\n",
        "# #     if training:\n",
        "#     classes, reconstructions = model(data, labels)\n",
        "# #     else:\n",
        "# #         classes, reconstructions = model(data)\n",
        "\n",
        "#     print(labels , classes)\n",
        "#     loss = capsule_loss(data, labels, classes, reconstructions)\n",
        "#     y_pred = classes.data.max(1)[1]\n",
        "#     y_true = data.data.max(1)[1]\n",
        "\n",
        "    \n",
        "#     correct += y_pred.eq(y_true).cpu().sum()\n",
        "#     test_loss /= len(test_loaders['test'])\n",
        "#     print('test acc = %.4f, test loss = %.5f' % (correct/len(test_loaders['test']), test_loss))\n",
        "# #     print('test acc = %.4f' % (test_acc))\n",
        "    \n",
        "#     return loss, classes\n",
        "running_loss = 0.0\n",
        "corr=[]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.cuda()\n",
        "def test_processor(sample):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    inputs, labels = sample\n",
        "    \n",
        "    inputs = inputs.unsqueeze(1).float()\n",
        "    labels = torch.LongTensor(labels)\n",
        "    labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "    \n",
        "    labels, inputs  = Variable(labels.float().cuda()), Variable(inputs.float().cuda())\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    classes, reconstructions = model(inputs)\n",
        "    \n",
        "    loss = capsule_loss(inputs, labels, classes, reconstructions)\n",
        "    _, preds = torch.max(classes.data, 1)\n",
        "    _, labb = torch.max(labels,1)\n",
        "#     loss = criterion(classes, labels)\n",
        "    running_loss += loss.data[0]\n",
        "\n",
        "    running_corrects += torch.sum(preds.cpu() == labb.cpu().data)\n",
        "    \n",
        "    corr.append(running_corrects)\n",
        "    epoch_loss = running_loss / len(test_loaders['test'])\n",
        "    epoch_acc = float(running_corrects) / len(test_loaders['test'])\n",
        "    print(' Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc*100))\n",
        "    print (sum(corr))\n",
        "    return epoch_loss, epoch_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3icTDQfZ7uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss,classes = test_processor(test_loaders['test'])\n",
        "engine.test(test_processor, test_loaders['test'])\n",
        "\n",
        "# print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "#     '195', meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "# test_loss, test_acc = test(model=model, test_loader=test_loaders['test'])\n",
        "\n",
        "# show_reconstruction(model, test_loader, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcLVeyaHZ7yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_dsets['test'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkAeIRm4ZmDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "engine.test(test_processor, test_loaders['test'])    \n",
        "\n",
        "test_state=torch.load('/data2/ar/gestures20170903/epoch/120160_layer/epoch_198.pt')\n",
        "test_loss_logger.log(test_state, meter_loss.value()[0])\n",
        "test_accuracy_logger.log(test_state, meter_accuracy.value()[0])\n",
        "confusion_logger.log(confusion_meter.value())\n",
        "\n",
        "print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "    test_state, meter_loss.value()[0], meter_accuracy.value()[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80NX4QIaZmFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    d,l =  next(iter(dset_loaders['train']))\n",
        "    tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
        "\n",
        "    return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjXYoMpZmHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get reconstructions\n",
        "images = []\n",
        "reconstructions = []\n",
        "for i in range(8):\n",
        "    image_tensor, label = dataset[i]\n",
        "    digit_caps = get_digit_caps(model, image_tensor)\n",
        "    reconstruction = get_reconstruction(model, digit_caps, label)\n",
        "    images.append(image_tensor.numpy()[0])\n",
        "    reconstructions.append(reconstruction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsP8pmKUaBEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot reconstructions\n",
        "fig, axs = plt.subplots(2, 8, figsize=(16, 4))\n",
        "axs[0, 0].set_ylabel('Org image', size='large')\n",
        "axs[1, 0].set_ylabel('Reconstruction', size='large')\n",
        "for i in range(8):\n",
        "    axs[0, i].imshow(images[i], cmap='gray')\n",
        "    axs[1, i].imshow(reconstructions[i], cmap='gray')\n",
        "    axs[0, i].set_yticks([])\n",
        "    axs[0, i].set_xticks([])\n",
        "    axs[1, i].set_yticks([])\n",
        "    axs[1, i].set_xticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr7I1sY6aBHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfoC1el1aBJt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6STdSuctaBL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCndBdRWaBN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXtqdYT3Zl-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlZC50XbZXju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr9JflR4HrbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dset = DicomFolder('/content/drive/'My Drive'/gestures/data/01/')\n",
        "test_dsets = {'test':test_dset}\n",
        "test_loaders = {x: DataLoader(test_dsets[x], batch_size=1,\n",
        "                            shuffle=True, num_workers=4) for x in ['test']}\n",
        "test_sizes = {x: len(test_dsets[x]) for x in ['test']}\n",
        "test_classes = dsets['train'].classes\n",
        "test_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRKUtIhHHrdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(input, dim=1):\n",
        "    transposed_input = input.transpose(dim, len(input.size()) - 1)\n",
        "    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)))\n",
        "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) - 1)\n",
        "\n",
        "\n",
        "def augmentation(x, max_shift=2):\n",
        "    _, _, height, width = x.size()\n",
        "\n",
        "    h_shift, w_shift = np.random.randint(-max_shift, max_shift + 1, size=2)\n",
        "    source_height_slice = slice(max(0, h_shift), h_shift + height)\n",
        "    source_width_slice = slice(max(0, w_shift), w_shift + width)\n",
        "    target_height_slice = slice(max(0, -h_shift), -h_shift + height)\n",
        "    target_width_slice = slice(max(0, -w_shift), -w_shift + width)\n",
        "\n",
        "    shifted_image = torch.zeros(*x.size())\n",
        "    shifted_image[:, :, source_height_slice, source_width_slice] = x[:, :, target_height_slice, target_width_slice]\n",
        "    return shifted_image.float()\n",
        "\n",
        "\n",
        "class CapsuleLayer(nn.Module):\n",
        "    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels, kernel_size=None, stride=None,\n",
        "                 num_iterations=NUM_ROUTING_ITERATIONS):\n",
        "        super(CapsuleLayer, self).__init__()\n",
        "\n",
        "        self.num_route_nodes = num_route_nodes\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        self.num_capsules = num_capsules\n",
        "\n",
        "        if num_route_nodes != -1:\n",
        "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n",
        "        else:\n",
        "            self.capsules = nn.ModuleList(\n",
        "                [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for _ in\n",
        "                 range(num_capsules)])\n",
        "\n",
        "    def squash(self, tensor, dim=-1):\n",
        "        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n",
        "        scale = squared_norm / (1 + squared_norm)\n",
        "        return scale * tensor / torch.sqrt(squared_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.num_route_nodes != -1:\n",
        "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
        "\n",
        "            logits = Variable(torch.zeros(*priors.size())).cuda()\n",
        "            for i in range(self.num_iterations):\n",
        "                probs = softmax(logits, dim=2)\n",
        "                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n",
        "\n",
        "                if i != self.num_iterations - 1:\n",
        "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
        "                    logits = logits + delta_logits\n",
        "        else:\n",
        "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
        "            outputs = torch.cat(outputs, dim=-1)\n",
        "            outputs = self.squash(outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class CapsuleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsuleNet, self).__init__()\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
        "#         self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32,\n",
        "#                                              kernel_size=9, stride=2)\n",
        "#         self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=32 * 52 *72, in_channels=8,\n",
        "#                                            out_channels=16)\n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
        "        self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=128,\n",
        "                                             kernel_size=9, stride=2)\n",
        "        self.primary_capsules2 = CapsuleLayer(num_capsules=8, num_route_nodes=128*52*72, in_channels=128, out_channels=32,\n",
        "                                             kernel_size=9, stride=2)\n",
        "        self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=32 * 22*32, in_channels=8,\n",
        "                                           out_channels=16)\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16 * NUM_CLASSES, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 120*160),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x = F.relu(self.conv1(x), inplace=True)\n",
        "        \n",
        "       \n",
        "        x = self.primary_capsules(x)\n",
        "        #print(x.size())\n",
        "        x = self.primary_capsules2(x)\n",
        "        z = self.digit_capsules(x)\n",
        "        #print(z.size())\n",
        "        x=z.squeeze().unsqueeze(0)\n",
        "        #x=z.squeeze().transpose(0, 1)\n",
        "        #print(x.size())\n",
        "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
        "        classes = F.softmax(classes)\n",
        "        #print(classes.size())\n",
        "        if y is None:\n",
        "            # In all batches, get the most active capsule.\n",
        "            _, max_length_indices = classes.max(dim=1)\n",
        "            y = Variable(torch.sparse.torch.eye(NUM_CLASSES)).cuda().index_select(dim=0, index=max_length_indices.data)\n",
        "  \n",
        "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
        "        #print(reconstructions.size())\n",
        "  \n",
        "        return classes, reconstructions\n",
        "\n",
        "\n",
        "class CapsuleLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsuleLoss, self).__init__()\n",
        "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
        "\n",
        "    def forward(self, images, labels, classes, reconstructions):\n",
        "        left = F.relu(0.9 - classes, inplace=True) ** 2\n",
        "        right = F.relu(classes - 0.1, inplace=True) ** 2\n",
        "\n",
        "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
        "        margin_loss = margin_loss.sum()\n",
        "\n",
        "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
        "\n",
        "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC1ayUMTHrgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from tqdm import tqdm\n",
        "import torchnet as tnt\n",
        "\n",
        "model = CapsuleNet()\n",
        "# model.load_state_dict(torch.load('epochs/epoch_327.pt'))\n",
        "model.cuda()\n",
        "\n",
        "print(\"# parameters:\", sum(param.numel() for param in model.parameters()))\n",
        "\n",
        "optimizer = Adam(model.parameters())\n",
        "\n",
        "engine = Engine()\n",
        "meter_loss = tnt.meter.AverageValueMeter()\n",
        "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n",
        "\n",
        "train_loss_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Train Loss'})\n",
        "train_error_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Train Accuracy'})\n",
        "test_loss_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Test Loss'})\n",
        "test_accuracy_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Test Accuracy'})\n",
        "confusion_logger = VisdomLogger('heatmap', opts={'title': '120160_layer2 Confusion matrix',\n",
        "                                                 'columnnames': list(range(NUM_CLASSES)),\n",
        "                                                 'rownames': list(range(NUM_CLASSES))})\n",
        "ground_truth_logger = VisdomLogger('image', opts={'title': '120160_layer2 Ground Truth'})\n",
        "reconstruction_logger = VisdomLogger('image', opts={'title': '120160_layer2 Reconstruction'})\n",
        "\n",
        "capsule_loss = CapsuleLoss()\n",
        "\n",
        "\n",
        "def get_iterator(mode):\n",
        "    \n",
        "    #dataset = MNIST(root='./data', download=True, train=mode)\n",
        "    #data = getattr(dataset, 'train_data' if mode else 'test_data')\n",
        "    #labels = getattr(dataset, 'train_labels' if mode else 'test_labels')\n",
        "\n",
        "    d,l =  next(iter(dset_loaders['train']))\n",
        "    tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
        "\n",
        "    return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n",
        "\n",
        "\n",
        "def processor(sample):\n",
        "    data, labels, training = sample\n",
        "\n",
        "    data = augmentation(data.unsqueeze(1).float() / 255.0)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "\n",
        "    data = Variable(data).cuda()\n",
        "    labels = Variable(labels).cuda()\n",
        "\n",
        "    if training:\n",
        "        classes, reconstructions = model(data, labels)\n",
        "    else:\n",
        "        classes, reconstructions = model(data)\n",
        "\n",
        "    loss = capsule_loss(data, labels, classes, reconstructions)\n",
        "\n",
        "    return loss, classes\n",
        "\n",
        "\n",
        "def reset_meters():\n",
        "    meter_accuracy.reset()\n",
        "    meter_loss.reset()\n",
        "    confusion_meter.reset()\n",
        "\n",
        "\n",
        "def on_sample(state):\n",
        "    state['sample'].append(state['train'])\n",
        "\n",
        "\n",
        "def on_forward(state):\n",
        "    meter_accuracy.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
        "    #print(state['output'].data.size())\n",
        "    #print(torch.LongTensor(state['sample'][1]).size())\n",
        "    one_hot = torch.eye(NUM_CLASSES)[torch.LongTensor(state['sample'][1])].type(torch.LongTensor).view(1,-1)\n",
        "    #print('onehot',one_hot)\n",
        "    #confusion_meter.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
        "    confusion_meter.add(state['output'].data, one_hot)\n",
        "    \n",
        "    meter_loss.add(state['loss'].data[0])\n",
        "\n",
        "\n",
        "def on_start_epoch(state):\n",
        "    reset_meters()\n",
        "    state['iterator'] = tqdm(state['iterator'])\n",
        "\n",
        "\n",
        "def on_end_epoch(state):\n",
        "    print('[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "\n",
        "    train_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
        "    train_error_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
        "\n",
        "    reset_meters()\n",
        "\n",
        "    #engine.test(processor, get_iterator(False))\n",
        "    engine.test(processor, dset_loaders['val'])    \n",
        "\n",
        "    test_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
        "    test_accuracy_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
        "    confusion_logger.log(confusion_meter.value())\n",
        "\n",
        "    print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "\n",
        "    torch.save(model.state_dict(), '/home/secl00/env_tensor112/0_Segmentation/gestures/epoch/06_ep/epoch_%d.pt' % state['epoch'])\n",
        "\n",
        "    # Reconstruction visualization.\n",
        "\n",
        "    test_sample = next(iter(dset_loaders['val']))\n",
        "\n",
        "    ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n",
        "    _, reconstructions = model(Variable(ground_truth).cuda())\n",
        "    reconstruction = reconstructions.cpu().view_as(ground_truth).data\n",
        "\n",
        "    ground_truth_logger.log(\n",
        "        make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
        "    reconstruction_logger.log(\n",
        "        make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
        "\n",
        "# def on_start(state):\n",
        "#     state['epoch'] = 327\n",
        "#\n",
        "# engine.hooks['on_start'] = on_start\n",
        "engine.hooks['on_sample'] = on_sample\n",
        "engine.hooks['on_forward'] = on_forward\n",
        "engine.hooks['on_start_epoch'] = on_start_epoch\n",
        "engine.hooks['on_end_epoch'] = on_end_epoch\n",
        "\n",
        "engine.train(processor, dset_loaders['train'], maxepoch=NUM_EPOCHS, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjg3sNlaJ3Or",
        "colab_type": "text"
      },
      "source": [
        "Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1oV0--BHriQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from tqdm import tqdm\n",
        "import torchnet as tnt\n",
        "\n",
        "model = CapsuleNet()\n",
        "# model.load_state_dict(torch.load('epochs/epoch_327.pt'))\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bu6dFLTHrkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.optim import Adam\n",
        "from torchnet.engine import Engine\n",
        "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from tqdm import tqdm\n",
        "import torchnet as tnt\n",
        "\n",
        "model = CapsuleNet()\n",
        "# model.load_state_dict(torch.load('epochs/epoch_327.pt'))\n",
        "model.cuda()\n",
        "\n",
        "print(\"# parameters:\", sum(param.numel() for param in model.parameters()))\n",
        "\n",
        "optimizer = Adam(model.parameters())\n",
        "\n",
        "engine = Engine()\n",
        "meter_loss = tnt.meter.AverageValueMeter()\n",
        "meter_accuracy = tnt.meter.ClassErrorMeter(accuracy=True)\n",
        "confusion_meter = tnt.meter.ConfusionMeter(NUM_CLASSES, normalized=True)\n",
        "\n",
        "train_loss_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Train Loss'})\n",
        "train_error_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Train Accuracy'})\n",
        "test_loss_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Test Loss'})\n",
        "test_accuracy_logger = VisdomPlotLogger('line', opts={'title': '120160_layer2 Test Accuracy'})\n",
        "confusion_logger = VisdomLogger('heatmap', opts={'title': '120160_layer2 Confusion matrix',\n",
        "                                                 'columnnames': list(range(NUM_CLASSES)),\n",
        "                                                 'rownames': list(range(NUM_CLASSES))})\n",
        "ground_truth_logger = VisdomLogger('image', opts={'title': '120160_layer2 Ground Truth'})\n",
        "reconstruction_logger = VisdomLogger('image', opts={'title': '120160_layer2 Reconstruction'})\n",
        "\n",
        "capsule_loss = CapsuleLoss()\n",
        "\n",
        "\n",
        "def get_iterator(mode):\n",
        "    \n",
        "    #dataset = MNIST(root='./data', download=True, train=mode)\n",
        "    #data = getattr(dataset, 'train_data' if mode else 'test_data')\n",
        "    #labels = getattr(dataset, 'train_labels' if mode else 'test_labels')\n",
        "\n",
        "    d,l =  next(iter(dset_loaders['train']))\n",
        "    tensor_dataset = tnt.dataset.TensorDataset([data, labels])\n",
        "\n",
        "    return tensor_dataset.parallel(batch_size=BATCH_SIZE, num_workers=4, shuffle=mode)\n",
        "\n",
        "\n",
        "def processor(sample):\n",
        "    data, labels, training = sample\n",
        "\n",
        "    data = augmentation(data.unsqueeze(1).float() / 255.0)\n",
        "    labels = torch.LongTensor(labels)\n",
        "\n",
        "    labels = torch.sparse.torch.eye(NUM_CLASSES).index_select(dim=0, index=labels)\n",
        "\n",
        "    data = Variable(data).cuda()\n",
        "    labels = Variable(labels).cuda()\n",
        "\n",
        "    if training:\n",
        "        classes, reconstructions = model(data, labels)\n",
        "    else:\n",
        "        classes, reconstructions = model(data)\n",
        "\n",
        "    loss = capsule_loss(data, labels, classes, reconstructions)\n",
        "\n",
        "    return loss, classes\n",
        "\n",
        "\n",
        "def reset_meters():\n",
        "    meter_accuracy.reset()\n",
        "    meter_loss.reset()\n",
        "    confusion_meter.reset()\n",
        "\n",
        "\n",
        "def on_sample(state):\n",
        "    state['sample'].append(state['train'])\n",
        "\n",
        "\n",
        "def on_forward(state):\n",
        "    meter_accuracy.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
        "    #print(state['output'].data.size())\n",
        "    #print(torch.LongTensor(state['sample'][1]).size())\n",
        "    one_hot = torch.eye(NUM_CLASSES)[torch.LongTensor(state['sample'][1])].type(torch.LongTensor).view(1,-1)\n",
        "    #print('onehot',one_hot)\n",
        "    #confusion_meter.add(state['output'].data, torch.LongTensor(state['sample'][1]))\n",
        "    confusion_meter.add(state['output'].data, one_hot)\n",
        "    \n",
        "    meter_loss.add(state['loss'].data[0])\n",
        "\n",
        "\n",
        "def on_start_epoch(state):\n",
        "    reset_meters()\n",
        "    state['iterator'] = tqdm(state['iterator'])\n",
        "\n",
        "\n",
        "def on_end_epoch(state):\n",
        "    print('[Epoch %d] Training Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "\n",
        "    train_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
        "    train_error_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
        "\n",
        "    reset_meters()\n",
        "\n",
        "    #engine.test(processor, get_iterator(False))\n",
        "    engine.test(processor, dset_loaders['val'])    \n",
        "\n",
        "    test_loss_logger.log(state['epoch'], meter_loss.value()[0])\n",
        "    test_accuracy_logger.log(state['epoch'], meter_accuracy.value()[0])\n",
        "    confusion_logger.log(confusion_meter.value())\n",
        "\n",
        "    print('[Epoch %d] Testing Loss: %.4f (Accuracy: %.2f%%)' % (\n",
        "        state['epoch'], meter_loss.value()[0], meter_accuracy.value()[0]))\n",
        "\n",
        "    torch.save(model.state_dict(), '/data2/ar/gestures20170903/epoch/120160_layer2/epoch_%d.pt' % state['epoch'])\n",
        "\n",
        "    # Reconstruction visualization.\n",
        "\n",
        "    test_sample = next(iter(dset_loaders['val']))\n",
        "\n",
        "    ground_truth = (test_sample[0].unsqueeze(1).float() / 255.0)\n",
        "    _, reconstructions = model(Variable(ground_truth).cuda())\n",
        "    reconstruction = reconstructions.cpu().view_as(ground_truth).data\n",
        "\n",
        "    ground_truth_logger.log(\n",
        "        make_grid(ground_truth, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
        "    reconstruction_logger.log(\n",
        "        make_grid(reconstruction, nrow=int(BATCH_SIZE ** 0.5), normalize=True, range=(0, 1)).numpy())\n",
        "\n",
        "# def on_start(state):\n",
        "#     state['epoch'] = 327\n",
        "#\n",
        "# engine.hooks['on_start'] = on_start\n",
        "engine.hooks['on_sample'] = on_sample\n",
        "engine.hooks['on_forward'] = on_forward\n",
        "engine.hooks['on_start_epoch'] = on_start_epoch\n",
        "engine.hooks['on_end_epoch'] = on_end_epoch\n",
        "\n",
        "engine.train(processor, dset_loaders['train'], maxepoch=NUM_EPOCHS, optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjl36cGuHnea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYGYFQlcHngw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jvZc49DHnX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}